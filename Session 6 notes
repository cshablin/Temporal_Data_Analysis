24/11/2021 - Session 6

tf normalization - normalize by the most frequent occurring word in the document

sax-vsm - closest centroid becomes the class of the test sample (cosine similarity is used)

why sax and not raw - it generalizes (and also in a way dimensionality reduction)


normalization based on most frequent sax term

10 papers as a minimum (at least 10. I would say 15 is safe)They can also be papers that were presented in class (provided it's relevant to what you're doing in the project)
look at the first zoom recording to know what should be in the literature survey ppt
You can also write the introduction + research questions (before the lit survey part)

Advice for writing papers :
- Introduction - motivation  + contribution (what you were trying to do new)
- Background (related works) - several sections - can be about the domain, if you work with patterns then sequential patterns mining
    try describing it like a story
- Methods:
- Evaluation:
  -- Research Questions
  -- Experimental Design
  -- Dataset
  -- Evaluation Metrics
- Results:
-Discussion


IEMiner similar to Karmalego but without transitivity
2 hrs and 9-10 min imp 
- perform mining separately in for each class. (search in PDF "karmalegos")
